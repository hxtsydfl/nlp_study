
---

###  四种文本分类方法优缺点对比表

| 方法                                                     | 优点                                                         | 缺点                                                         |
| -------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **1. 正则（Rule-based / Regex）**                        | - 实现简单，开发成本低<br>- 推理速度极快<br>- 完全可解释，易于审计<br>- 无需训练数据或模型 | - 泛化能力差，无法处理语义变体<br>- 维护成本高，规则易冲突<br>- 覆盖不全，准确率低<br>- 依赖人工经验，难以扩展 |
| **2. TF-IDF + 传统模型**<br>（如逻辑回归、SVM）          | - 实现简单，训练快<br>- 资源消耗低，适合部署<br>- 可解释性较好（可查看关键词权重）<br>- 在中小数据集上表现稳定 | - 忽略语序和上下文语义<br>- 词汇表外词（OOV）无法处理<br>- 特征稀疏，性能上限低<br>- 对复杂语义任务效果差 |
| **3. BERT 微调**<br>（如 BERT, RoBERTa）                 | - 语义理解能力强，准确率高<br>- 支持迁移学习，小数据也能表现好<br>- 在多种任务上达到 SOTA<br>- 支持多语言和复杂表达 | - 训练和推理资源消耗大（需 GPU）<br>- 模型“黑箱”，可解释性差<br>- 部署复杂，模型体积大<br>- 需要一定量标注数据 |
| **4. Prompt + 大模型 API**<br>（如 GPT-4, Qwen, Claude） | - 无需训练，零样本即可工作<br>- 语义理解极强，支持复杂推理<br>- 开发极快，只需设计 Prompt<br>- 分类体系变更灵活 | - 调用成本高（按 token 计费）<br>- 延迟高，依赖网络<br>- 输出不稳定，需精心设计 Prompt<br>- 数据隐私风险（需外传）<br>- 不适合高吞吐场景 |

---

### 
- **“正则”**：适用于规则明确、表达固定的场景。
- **“TF-IDF”**：适合快速原型或资源受限环境，是传统 NLP 的经典方法。
- **“BERT”**：工业级主流方案，适合追求高精度且有标注数据的项目。
- **“Prompt + 大模型”**：适合少样本、快速验证、分类体系频繁变更的场景，但长期使用成本高。

---

