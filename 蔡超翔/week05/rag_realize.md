

# RAG 系统实现流程

## 一、核心架构

RAG（Retrieval-Augmented Generation）系统采用三层架构设计，确保高效检索与高质量生成：

| 层级 | 职责 |
|------|------|
| **文档处理层** | 负责文件解析、文本提取与智能分块 |
| **检索层** | 实现混合检索（关键词 + 向量），提升召回精度 |
| **生成层** | 基于检索结果调用大模型生成自然语言回答 |

---

## 二、完整工作流程

### 1. 文档预处理阶段

#### 文件解析
- 支持格式：PDF、Word（当前主要实现 PDF）
- 解析工具：`pdfplumber`
- 功能：
  - 逐页提取原始文本内容
  - 保留段落结构与换行信息
  - 提取文档元数据（如标题、作者、页数）

#### 智能分块
- 算法：滑动窗口（固定块大小 + 重叠区域）
- 参数示例：
  - 块大小：512 tokens
  - 重叠区：64 tokens
- 输出：
  - `chunks`：分块后的文本片段
  - `full_pages`：原始页面内容（用于上下文补充）

#### 向量化存储
- 嵌入模型：BGE 系列（如 `bge-large-zh-v1.5`）
- 向量维度：1024 维
- 存储方案：Elasticsearch
  - `chunk_info` 索引：
    - 字段：`text`, `vector`, `doc_id`, `page_num`, `chunk_idx`
  - `document_meta` 索引：
    - 字段：`doc_id`, `title`, `file_path`, `upload_time`, `page_count`

---

### 2. 查询处理阶段

#### 混合检索机制
并行执行两种检索方式，充分发挥各自优势：

| 检索类型 | 方法 | 工具 |
|--------|------|------|
| **关键词检索** | BM25 算法 | Elasticsearch 原生全文搜索 |
| **向量检索** | kNN 近邻搜索 | Elasticsearch kNN search / Approximate Nearest Neighbor |

#### 结果融合
- 策略：RRF（Reciprocal Rank Fusion）
- 公式：  
  $$
  \text{score} = \frac{1}{\text{rank} + 60}
  $$
- 步骤：
  1. 分别对关键词和向量结果排序
  2. 计算每个文档的 RRF 得分
  3. 按总分重新排序，取 Top-K（如 K=5）

#### 可选重排序（Re-Ranking）
- 模型：`BGE reranker`（如 `bge-reranker-large`）
- 输入：用户查询 + Top-N 初始结果
- 输出：精排后的相关性得分
- 目的：进一步提升关键片段的排序优先级

---

### 3. 回答生成阶段

#### 提示词工程（Prompt Engineering）
使用结构化模板构造输入提示：

```text
【当前时间】{{current_time}}

【相关文档】
{{retrieved_context}}

【用户问题】
{{user_query}}

【指令】
请基于以上信息回答问题。若无法从文档中找到答案，请明确回复“根据现有资料无法回答该问题”。
```

#### 大模型调用
- 接口兼容：OpenAI API 格式
- 支持模型：Qwen、DeepSeek、GLM、通义千问等
- 可配置参数：
  - `temperature`: 0.9
  - `top_p`: 0.7
  - `max_tokens`: 1024
- 对话管理：
  - 支持多轮对话历史缓存
  - 上下文拼接策略防止丢失语义

---

## 三、关键设计特点

| 特点 | 说明 |
|------|------|
| **混合检索** | 融合 BM25 与向量检索，兼顾精确匹配与语义理解 |
| **灵活分块** | 滑动窗口+重叠机制，平衡上下文完整性与检索粒度 |
| **模块化设计** | 各组件（解析、分块、检索、生成）可通过配置文件独立替换 |
| **容错机制** | 明确处理“无答案”场景，避免模型幻觉 |
| **可扩展性** | 支持新增文档类型、嵌入模型、大模型后端 |

---

