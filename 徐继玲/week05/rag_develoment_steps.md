# 数据准备 (离线处理)
此阶段是为智能问答系统准备“知识大脑”，确保政府文件和FAQ等内容能被高效检索。
## 文档加载与清洗
使用文档加载器从各种来源（PDF、Word、HTML、数据库等）加载原始政府文件和FAQ。随后进行数据清洗，包括去重、去噪、格式标准化（如全角转半角），并可能为文本添加元数据（如发文单位、发布日期、政策类别）
## 文本分割 (Text Splitting)
这是关键步骤，直接影响后续检索精度。
需根据文档类型选择分块策略：
- 政府长文档：适合采用递归分块（按段落→句子优先级分割）或结构分块（利用章节标题等天然结构），并设置10-15%的重叠窗口以保持上下文连贯，块大小通常为300-500词 
- FAQ：通常每条问答对已自然分割，可直接作为单个文本块，或稍作整合。
## 向量化 (Embedding)
使用嵌入模型（如 BGE-large-zh, text-embedding-ada-002）将每个文本块转换为高维向量（如768维或1536维），这个过程捕获了文本的语义信息
## 向量存储与索引
将生成的向量和对应的原始文本（及元数据）存入向量数据库（如Chroma, Milvus, FAISS）。这类数据库支持高效的相似性搜索，便于后续快速检索
# 实时检索
当用户提出问题时，系统会执行以下步骤：
## 查询向量化
将用户的自然语言查询（query）使用与知识库相同的嵌入模型进行向量化，将其转换为一个查询向量
## 相似性检索
在向量数据库中，通过计算余弦相似度等度量方式，快速查找与查询向量最相似的K个文本块（Top-K）。这些被检索到的文本块即为与问题相关的上下文信息 
## 高级检索策略
为提升检索精度，常采用以下策略：
- 混合检索 (Hybrid Search）：结合稠密向量检索（语义相似）和稀疏检索（如BM25，关键词匹配）。
- 重排序 (Reranking)：在初步检索出大量结果（如Top-20）后，使用一个更精细的重排序模型（如交叉编码器）对结果进行再次精排，筛选出最相关的几个片段（如Top-3）送给LLM。
# 增强生成与多轮问答
这是RAG体现其价值的关键阶段，它将检索到的信息与LLM的能力相结合，并支持多轮对话。
- 构建增强提示 (Prompt Engineering)：将检索到的相关文本片段（作为上下文）与用户的原始查询巧妙地拼接成一个详细的提示（prompt），然后输入给LLM。
- 生成最终答案：LLM基于这个富含相关上下文的增强提示来生成最终答案。由于答案源于提供的政府知识库，其准确性更高，并且通常可以追溯答案来源
- 支持多轮问答：为了实现多轮对话，系统需要：
  - 维护对话历史：通过问答模块的存储接口存储和管理当前会话的历史记录。
  - 在检索时考虑历史上下文：当用户进行后续提问时，可以将上一轮的回答或整个对话历史作为新的查询条件的一部分，或将其作为过滤器，从知识库中检索更相关的内容。这使系统能理解指代和后续问题 
